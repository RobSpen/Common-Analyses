{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45c7835",
   "metadata": {},
   "source": [
    "# Mixed Design Factorial ANOVA\n",
    "\n",
    "A mixed factorial design involves more than one independent variable (IV) and contains both independent groups (between-subjects) variables and repeated measures (within-subjects) variables. \n",
    "In this notebook I will analyse a dataset that used a mixed factorial design with one repeated measures IV (with three levels/ conditions) and one independent groups IV (with two levels/ conditions). The study used a 2x3 mixed ANOVA design and investigated the effectiveness of polygraph methods for detecting lies. The repeated measures IV, called questions, recorded whether a participant told the truth (truth), told a lie (lie), or completed a control task (control) in response to a series of questions asked by the researcher. Lying and telling the truth were self-reported by participants after the study. The second IV, which was the independent groups factor called framing, assessed whether the framing of the effectiveness of polygraph methods for detecting lies influenced the results. For this IV half of the participants were primed with a sceptical view of the effectiveness of the polygraph before the study was conducted and half were primed with a positive view suggesting the method was a highly accurate technique for detecting lies. The research assessed whether there were differences on a dependent variable (DV) of mean arousal, measured by participants heart rate, when they told the truth, lied, completed the control task. Further, an assessment was made of whether mean arousal differed between levels of the framing condition. \n",
    "\n",
    "- IV1: Questions (3 levels: Lie/ Truth/ Control) - Repeated measures.\n",
    "- IV2: Framing (2 levels: Positive/ Sceptical ) - Independent groups.\n",
    "\n",
    "- DV - Heart Rate mean arousal. \n",
    "\n",
    "In the following sections I will conduct a mixed ANOVA analysis on the data, including tests of assumptions, ANOVA model, and any post-hoc or simple effects tests that may be required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbaced10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing key software libraries. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185728d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>framing</th>\n",
       "      <th>questions</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>58.536483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>74.968975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>61.114431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>60.214866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>61.410426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  framing questions    arousal\n",
       "0   1        1       lie  58.536483\n",
       "1   2        1       lie  74.968975\n",
       "2   3        1       lie  61.114431\n",
       "3   4        1       lie  60.214866\n",
       "4   5        1       lie  61.410426"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset.\n",
    "\n",
    "hr_df = pd.read_csv('hr_polygraph_long.csv')\n",
    "\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878ab4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         240 non-null    int64  \n",
      " 1   framing    240 non-null    int64  \n",
      " 2   questions  240 non-null    object \n",
      " 3   arousal    240 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "hr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fb147",
   "metadata": {},
   "source": [
    "The data is in the long format which will make it easier to work with during the analysis. The only thing it is currently missing is category labels for the framing variable. This has been given a numberical code of 1 for the scepctical and 2 for the positive group. It would be useful to have this variable saved as a categorical object with the appropriate labels. This will help with interpreting the output later on and avoid confusion about which group was coded as 1 and which was coded as 2. The easiest way for me to deal with this is to create a new variable that maps the integer values in the framing variable to labels using the series.map method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfe717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new variable that represent the category labels for framing\n",
    "# and appending them to the dataframe. \n",
    "\n",
    "# Using the series.map function to add labels to the categorical variable.\n",
    "\n",
    "a = [1, 2]\n",
    "b = [\"sceptical\", \"positive\"]\n",
    "\n",
    "hr_df['framing_cat'] = hr_df['framing'].map(dict(zip(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e76a52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>framing</th>\n",
       "      <th>questions</th>\n",
       "      <th>arousal</th>\n",
       "      <th>framing_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>58.536483</td>\n",
       "      <td>sceptical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>74.968975</td>\n",
       "      <td>sceptical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>61.114431</td>\n",
       "      <td>sceptical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>60.214866</td>\n",
       "      <td>sceptical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>lie</td>\n",
       "      <td>61.410426</td>\n",
       "      <td>sceptical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  framing questions    arousal framing_cat\n",
       "0   1        1       lie  58.536483   sceptical\n",
       "1   2        1       lie  74.968975   sceptical\n",
       "2   3        1       lie  61.114431   sceptical\n",
       "3   4        1       lie  60.214866   sceptical\n",
       "4   5        1       lie  61.410426   sceptical"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c22d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           240 non-null    int64  \n",
      " 1   framing      240 non-null    int64  \n",
      " 2   questions    240 non-null    object \n",
      " 3   arousal      240 non-null    float64\n",
      " 4   framing_cat  240 non-null    object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "hr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62db97d",
   "metadata": {},
   "source": [
    "With the new framing categorical variable appended to the dataset, I can now start the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4443fd",
   "metadata": {},
   "source": [
    "### Tests of Assumptions\n",
    "\n",
    "As we have both a independent groups IV and a repeated measures IV I will need to conduct both a Levene's test and Mauchly's tests of sphericity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888eac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>pval</th>\n",
       "      <th>equal_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>levene</th>\n",
       "      <td>5.605824</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               W      pval  equal_var\n",
       "levene  5.605824  0.018701      False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conducting Levene's test on the framing IV. \n",
    "\n",
    "pg.homoscedasticity(hr_df, dv = 'arousal', group = 'framing_cat', center = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b17b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpherResults(spher=False, W=0.8817264823613956, chi2=9.818123778136291, dof=2, pval=0.007379407788368307)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running Mauchly's test on the questions IV using the pg.sphericity method. \n",
    "\n",
    "pg.sphericity(data = hr_df, dv = 'arousal', subject = 'id', within = ['questions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f4dbd",
   "metadata": {},
   "source": [
    "This is somewhat problematic as we can see above that we cannot assume equal variances for the independent groups factor, nor can we assume sphericity for the repeared measures factor. \n",
    "- Levene's test: F(1, 78) = 5.61, p = 0.02 \n",
    "- Mauchly's test: W = 0.88, X2(2) = 9,82, p = 0.007\n",
    "\n",
    "I will run the mixed design ANOVA using the pingouin mixed_anova method and will use an adjusted p-value where necessary to interpret the significance of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb2bd3",
   "metadata": {},
   "source": [
    "### 2x3 Mixed ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "856da809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF1</th>\n",
       "      <th>DF2</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-GG-corr</th>\n",
       "      <th>np2</th>\n",
       "      <th>eps</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>W-spher</th>\n",
       "      <th>p-spher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>framing_cat</td>\n",
       "      <td>1221.208119</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1221.208119</td>\n",
       "      <td>4.092105</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>questions</td>\n",
       "      <td>1856.868503</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>928.434252</td>\n",
       "      <td>3.617132</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.051769</td>\n",
       "      <td>0.044318</td>\n",
       "      <td>0.894236</td>\n",
       "      <td>False</td>\n",
       "      <td>0.881726</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interaction</td>\n",
       "      <td>6638.402957</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>3319.201478</td>\n",
       "      <td>12.931438</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source           SS  DF1  DF2           MS          F     p-unc  \\\n",
       "0  framing_cat  1221.208119    1   78  1221.208119   4.092105  0.046511   \n",
       "1    questions  1856.868503    2  156   928.434252   3.617132  0.029136   \n",
       "2  Interaction  6638.402957    2  156  3319.201478  12.931438  0.000006   \n",
       "\n",
       "   p-GG-corr       np2       eps sphericity   W-spher   p-spher  \n",
       "0        NaN  0.049848       NaN        NaN       NaN       NaN  \n",
       "1   0.051769  0.044318  0.894236      False  0.881726  0.007379  \n",
       "2        NaN  0.142211       NaN        NaN       NaN       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_res = pg.mixed_anova(data = hr_df, dv = 'arousal', within = 'questions', subject = 'id', \n",
    "                        between = 'framing_cat')\n",
    "\n",
    "mix_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d59b7",
   "metadata": {},
   "source": [
    "We can see from the above results that we have a significant main effect of framing when using the uncorrected p-value (F(1, 78) = 4.09, p = 0.05). A significant main effect of questions, using the Greenhouse-Geisser corrected p-value (F(2, 156) = 3.62, p = 0.05) and a highly significant interaction between framing and questions, using hte uncorrected p-value (F(2, 256) = 12.93, p < 0.0001. Although we do not have an adjusted p-value for the interaction term the extremely small p-value suggests it will still be significant following a robust test. As the interaction is significant this indicates that the main effects, although significant, are likely to be inconsistent. The next step is to conduct tests of simple effects to interpret the significant interaction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd00f4f",
   "metadata": {},
   "source": [
    "### Simple Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb503a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='questions', ylabel='arousal'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating an interaction plot to visualise the differences between the group means using seaborn pointplot.\n",
    "\n",
    "sns.set()\n",
    "sns.pointplot(data = hr_df, x = 'questions', y = 'arousal', hue = 'framing_cat', dodge = True, \n",
    "              markers = ['o', 's'], capsize = 1, errwidth = 1, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e82fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next obtaining descriptive statistics by interaction group for comparison. \n",
    "\n",
    "# Creating a new object for each of the interaction groups:\n",
    "\n",
    "scep_lie = hr_df.loc[(hr_df['framing_cat'] == 'sceptical') & (hr_df['questions'] == 'lie')]['arousal']\n",
    "scep_truth = hr_df.loc[(hr_df['framing_cat'] == 'sceptical') & (hr_df['questions'] == 'truth')]['arousal']\n",
    "scep_contr = hr_df.loc[(hr_df['framing_cat'] == 'sceptical') & (hr_df['questions'] == 'control')]['arousal']\n",
    "pos_lie = hr_df.loc[(hr_df['framing_cat'] == 'positive') & (hr_df['questions'] == 'lie')]['arousal']\n",
    "pos_truth = hr_df.loc[(hr_df['framing_cat'] == 'positive') & (hr_df['questions'] == 'truth')]['arousal']\n",
    "pos_contr = hr_df.loc[(hr_df['framing_cat'] == 'positive') & (hr_df['questions'] == 'control')]['arousal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2aae6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sceptical & Lie: 69.28\n",
      "Sceptical & Truth: 74.90\n",
      "Sceptical & Control: 74.15\n",
      "Positive & Lie: 88.38\n",
      "Positive & Truth: 69.60\n",
      "Positive & Control: 73.88\n"
     ]
    }
   ],
   "source": [
    "# Printing the mean for each of the above interaction group objects. \n",
    "\n",
    "print(f\"Sceptical & Lie: {scep_lie.mean():.2f}\")\n",
    "print(f\"Sceptical & Truth: {scep_truth.mean():.2f}\")\n",
    "print(f\"Sceptical & Control: {scep_contr.mean():.2f}\")\n",
    "\n",
    "print(f\"Positive & Lie: {pos_lie.mean():.2f}\")\n",
    "print(f\"Positive & Truth: {pos_truth.mean():.2f}\")\n",
    "print(f\"Positive & Control: {pos_contr.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8138b2",
   "metadata": {},
   "source": [
    "Inspection of the above interaction plot indicates that there is a significant difference in arousal between the sceptical and positive framing conditions when participants lied. With those given a positive framing of how effective the technique is for detecting lies experiencing significantly higher arousal. However, there does not seem to be a significant difference between framing conditions at the truth and control levels. When considering the sceptical group (blue line) in isolation there also does not appear to be a signficant difference in arousal between the lie, truth, and control conditions, as indicated by the large degree of overlap between the error bars (95% confidence intervals). Looking only at the positive group (orange line), however, we see that arousal seems to be significantly higher in the lie condition when compared to the truth and control condition. Further, the truth and control condition do not seem to differ signficantly. \n",
    "\n",
    "Tests of simple effects, in the form of pairwise comparisons, can be conducted to assess which differences between groups are statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ceb8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>questions</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-corr</th>\n",
       "      <th>p-adjust</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>control</td>\n",
       "      <td>lie</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.626385</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.107850</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.257469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>control</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.801622</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.425176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.108861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>lie</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.252364</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>0.081224</td>\n",
       "      <td>bonf</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.382085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>framing_cat</td>\n",
       "      <td>-</td>\n",
       "      <td>positive</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.022895</td>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.447970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>questions * framing_cat</td>\n",
       "      <td>control</td>\n",
       "      <td>positive</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.945696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.015132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>questions * framing_cat</td>\n",
       "      <td>lie</td>\n",
       "      <td>positive</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.004393</td>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>bonf</td>\n",
       "      <td>4552.783</td>\n",
       "      <td>1.108222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>questions * framing_cat</td>\n",
       "      <td>truth</td>\n",
       "      <td>positive</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.661068</td>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.100715</td>\n",
       "      <td>0.302144</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.764</td>\n",
       "      <td>-0.367843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Contrast questions         A          B Paired  Parametric  \\\n",
       "0                questions         -   control        lie   True        True   \n",
       "1                questions         -   control      truth   True        True   \n",
       "2                questions         -       lie      truth   True        True   \n",
       "3              framing_cat         -  positive  sceptical  False        True   \n",
       "4  questions * framing_cat   control  positive  sceptical  False        True   \n",
       "5  questions * framing_cat       lie  positive  sceptical  False        True   \n",
       "6  questions * framing_cat     truth  positive  sceptical  False        True   \n",
       "\n",
       "          T   dof alternative     p-unc    p-corr p-adjust      BF10    hedges  \n",
       "0 -1.626385  79.0   two-sided  0.107850  0.323551     bonf     0.434 -0.257469  \n",
       "1  0.801622  79.0   two-sided  0.425176  1.000000     bonf     0.168  0.108861  \n",
       "2  2.252364  79.0   two-sided  0.027075  0.081224     bonf     1.332  0.382085  \n",
       "3  2.022895  78.0   two-sided  0.046511       NaN      NaN     1.345  0.447970  \n",
       "4 -0.068332  78.0   two-sided  0.945696  1.000000     bonf     0.233 -0.015132  \n",
       "5  5.004393  78.0   two-sided  0.000003  0.000010     bonf  4552.783  1.108222  \n",
       "6 -1.661068  78.0   two-sided  0.100715  0.302144     bonf     0.764 -0.367843  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running pairwise comparisons using the pingouin pairwise_tests method. \n",
    "# I here run a Bonferroni adjustment to make the test stricter as a result of the lack of homogeneity of variance and\n",
    "# sphericity in the dataset. \n",
    "\n",
    "simple_eff = pg.pairwise_tests(data = hr_df, dv = 'arousal', between = 'framing_cat', \n",
    "                               within = 'questions', subject = 'id', padjust = 'bonf')\n",
    "\n",
    "simple_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba3536",
   "metadata": {},
   "source": [
    "Note that the above output only gives us three of our simple effects comparisons that we wish to make. Ignoring the first four rows (indexed 0 to 3) that relate to main effects, we can see that pairwise comparisons have been conducted holding each level of questions constant and comparing the framing conditions. We can see from this that the positive and sceptical group means are not statistically significantly different in the control condition; the positive an sceptical group means are significantly different in the lie condition; and are not significantly different in the truth condition. \n",
    "\n",
    "Making use fo the group means printed above we can formally report these results as:\n",
    "\n",
    "- Control: Positive (Mean = 73.88) V Sceptical (Mean = 74.15). Not significantly different (t(78) = 0.07, p = 1.000)\n",
    "- Lie: Positive (Mean = 88.38) V Sceptical (Mean = 69.28). Significantly different (t(78) = 5.00, p < 0.0001)\n",
    "- Truth: Positive (Mean = 69.60) V Sceptical (Mean = 74.90). Not significantly different (t(78) = 1.66, p = 0.30)\n",
    "\n",
    "There are further test we would like to run holding each framing group constant and comparing the three questions conditions. In order to do this we can run the above pairwise tests again but this time specify a parameter that within_first = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e79bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>framing_cat</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-corr</th>\n",
       "      <th>p-adjust</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>framing_cat</td>\n",
       "      <td>-</td>\n",
       "      <td>positive</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.022895</td>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345</td>\n",
       "      <td>0.447970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>control</td>\n",
       "      <td>lie</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.626385</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.107850</td>\n",
       "      <td>0.323551</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.434</td>\n",
       "      <td>-0.257469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>control</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.801622</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.425176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.108861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>questions</td>\n",
       "      <td>-</td>\n",
       "      <td>lie</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.252364</td>\n",
       "      <td>79.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>0.081224</td>\n",
       "      <td>bonf</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.382085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>positive</td>\n",
       "      <td>control</td>\n",
       "      <td>lie</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.809326</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>bonf</td>\n",
       "      <td>58.628</td>\n",
       "      <td>-0.742130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>positive</td>\n",
       "      <td>control</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.367253</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.254567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>positive</td>\n",
       "      <td>lie</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.859113</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>bonf</td>\n",
       "      <td>1084.92</td>\n",
       "      <td>1.093518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>control</td>\n",
       "      <td>lie</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.209247</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.233848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.315339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>control</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.241590</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.810364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.047347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>framing_cat * questions</td>\n",
       "      <td>sceptical</td>\n",
       "      <td>lie</td>\n",
       "      <td>truth</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.619680</td>\n",
       "      <td>39.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.680163</td>\n",
       "      <td>bonf</td>\n",
       "      <td>0.565</td>\n",
       "      <td>-0.388181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Contrast framing_cat         A          B Paired  \\\n",
       "0              framing_cat           -  positive  sceptical  False   \n",
       "1                questions           -   control        lie   True   \n",
       "2                questions           -   control      truth   True   \n",
       "3                questions           -       lie      truth   True   \n",
       "4  framing_cat * questions    positive   control        lie   True   \n",
       "5  framing_cat * questions    positive   control      truth   True   \n",
       "6  framing_cat * questions    positive       lie      truth   True   \n",
       "7  framing_cat * questions   sceptical   control        lie   True   \n",
       "8  framing_cat * questions   sceptical   control      truth   True   \n",
       "9  framing_cat * questions   sceptical       lie      truth   True   \n",
       "\n",
       "   Parametric         T   dof alternative     p-unc    p-corr p-adjust  \\\n",
       "0        True  2.022895  78.0   two-sided  0.046511       NaN      NaN   \n",
       "1        True -1.626385  79.0   two-sided  0.107850  0.323551     bonf   \n",
       "2        True  0.801622  79.0   two-sided  0.425176  1.000000     bonf   \n",
       "3        True  2.252364  79.0   two-sided  0.027075  0.081224     bonf   \n",
       "4        True -3.809326  39.0   two-sided  0.000482  0.002893     bonf   \n",
       "5        True  1.367253  39.0   two-sided  0.179375  1.000000     bonf   \n",
       "6        True  4.859113  39.0   two-sided  0.000020  0.000117     bonf   \n",
       "7        True  1.209247  39.0   two-sided  0.233848  1.000000     bonf   \n",
       "8        True -0.241590  39.0   two-sided  0.810364  1.000000     bonf   \n",
       "9        True -1.619680  39.0   two-sided  0.113360  0.680163     bonf   \n",
       "\n",
       "      BF10    hedges  \n",
       "0    1.345  0.447970  \n",
       "1    0.434 -0.257469  \n",
       "2    0.168  0.108861  \n",
       "3    1.332  0.382085  \n",
       "4   58.628 -0.742130  \n",
       "5    0.403  0.254567  \n",
       "6  1084.92  1.093518  \n",
       "7    0.336  0.315339  \n",
       "8    0.175 -0.047347  \n",
       "9    0.565 -0.388181  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running pairwise comparisons againusing the pingouin pairwise_tests method. \n",
    "# I here run a Bonferroni adjustment to make the test stricter as a result of the lack of homogeneity of variance and\n",
    "# sphericity in the dataset. \n",
    "# Note the difference to the above syntax. Here I have added another argument specifying within_first = False. \n",
    "\n",
    "simple_eff2 = pg.pairwise_tests(data = hr_df, dv = 'arousal', between = 'framing_cat', \n",
    "                               within = 'questions', subject = 'id', padjust = 'bonf', within_first = False)\n",
    "\n",
    "simple_eff2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45426f66",
   "metadata": {},
   "source": [
    "In this second output table we can see that framing has been used as the variable held constant and each of the levels of questions are being compared. These results show that in the positive condition control and lie have significantly different mean arousal and lie and truth have significantly different mean arousal. However, control and truth do not have significantly different mean arousal. When consindering the sceptical condition in isolation we can see that none of the questions levels are significantly different form one another. These results confirm what we could see in the interaction plot as the sceptical (blue line) line was almost completely flat. \n",
    "\n",
    "The results of these comparisons are summarised below: \n",
    "\n",
    "- Positive: Control (Mean = 73.88) V Lie (Mean = 88.38). Significantly different (t(39) = 3.81, p = 0.0029).\n",
    "- Positive: Control (Mean = 73.88) V Truth (Mean = 69.60). Not significantly different (t(39) = 1.37, p = 1.000).\n",
    "- Positive: Lie (Mean = 88.38) V Truth (Mean = 69.60). Significantly different (t(39) = 4.86, p = 0.0001).\n",
    "\n",
    "- Sceptical: Control (Mean = 74.15) V Lie (Mean = 69.28). Not significantly different (t(39) = 1.21, p = 1.000).\n",
    "- Sceptical: Control (Mean = 74.15) V Truth (Mean = 74.90). Not significantly different (t(39) = 0.24, p = 1.000).\n",
    "- Sceptical: Lie (Mean = 69.28) V Truth (Mean = 74.90). Not significantly different (t(39) = 1.62, p = 0.68). \n",
    "\n",
    "Overall, these results indicate that framing can influence the results of a lie detector test and only participants who have been given a positive framing of how effective it is as a technique are likely to experience higher arousal when telling lies. However, if participants are given a sceptical framing and led to believe the method is not effective, they are likely to experience lower or normal levels of arousal when that are no different to when they tell the truth. These results indicate that the administrator of a lie detector test can influence the results based on the belief they can induce in the participant and this method is not a reliable technique for detecting lies.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
