{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41649beb",
   "metadata": {},
   "source": [
    "# Tests of Assumptions for ANOVA\n",
    "\n",
    "Before running an Analysis of Variance (ANOVA) statistical model there are a number of assumptions that should be checked in relation to the data. Standard ANOVA tests assume that the data being compared is suitable for parametric statistical tests. It is often worth checking the data meets these assumptions before running an ANOVA as unsuitable data can lead to erroneous results and findings. \n",
    "\n",
    "### Common tests of assumptions for ANOVA are:\n",
    "\n",
    "- Tests of homogeneity of variance (equal variances) for independent groups (between-subjects) designs. This is to check the assumption that the different groups that are being compared have the same (roughly equal) variances around the group means. A frequently used test for this is Levene's test for homogeneity of variance. \n",
    "\n",
    "- Tests of sphericity for repeated measures (within-subjects) designs. This is the repeated measures equivalent of the independent groups test for homogeneity of variance. Sphericity can be defined as the assumption that the variances of differences between scores across groups for data taken from the same participant are equal. A commonly used test of sphericity in repeated measures designs is Mauchly's test of sphericity. \n",
    "\n",
    "- Tests of normality. These tests assess the extent to which the distribution of scores for a variable differs from a normal distribution. Normally distributed data is an assumption for all parametric statistical tests for it is necessary for both independent groups and repeated measures ANOVA designs. The Shapiro -Wilk test is a test of normality, where a significant value indicates deviation of the data from a normal distribution. \n",
    "\n",
    "All of the above tests have limitations and there are many debates about their value. For example, statistical tests assessing both normality and the equality of variances can be sensitive to differences in sample size, with larger sample sizes making it possible to detect as statistically significant quite small differences (in terms of variance or deviation from normality) that will not actually be problematic or invalidate the results of the ANOVA model. \n",
    "\n",
    "In this notebook I will demonstrate how to conduct Levene's test (Homogeneity of variance), Mauchly's test (Sphericity), and the Shapiro-Wilk test (Normality) using the scipy and pingouin statistical packages in python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9a70a",
   "metadata": {},
   "source": [
    "## Levene's Test for Homogeneity of Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc352a4",
   "metadata": {},
   "source": [
    "I will conduct the Levene's test using the levene method from the scipy.stats library. This allows me to specify that the mean is used as the measure of centre for the test. If we use the pingouin package to run Levene's test, by default it uses the median and is thereby conducting a Brown-Forsyth test. In this case we just want to use the mean for a standard Levene's test, so will use scipy.stats for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2acedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the key software libraries.\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9088bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Dose</th>\n",
       "      <th>Happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Person  Dose  Happiness\n",
       "0        1     1          3\n",
       "1        2     1          2\n",
       "2        3     1          1\n",
       "3        4     1          1\n",
       "4        5     1          4\n",
       "5        6     2          5\n",
       "6        7     2          2\n",
       "7        8     2          4\n",
       "8        9     2          2\n",
       "9       10     2          3\n",
       "10      11     3          7\n",
       "11      12     3          4\n",
       "12      13     3          5\n",
       "13      14     3          3\n",
       "14      15     3          6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing a dataset to work with. \n",
    "\n",
    "df_ig = pd.read_csv('Puppies.csv')\n",
    "\n",
    "df_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa057f",
   "metadata": {},
   "source": [
    "As we can see this is only a small dataset with 15 participants. It contains a categorical variable 'Dose' which is currently shown as numerical values (1, 2, and 3). These three values correspond to categories of Low, Medium, and High. The first thing I will do is create a further variable where these numbers are actually labelled with the appropriate category name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91f04eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Dose</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Dose_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Person  Dose  Happiness Dose_cat\n",
       "0        1     1          3      Low\n",
       "1        2     1          2      Low\n",
       "2        3     1          1      Low\n",
       "3        4     1          1      Low\n",
       "4        5     1          4      Low\n",
       "5        6     2          5   Medium\n",
       "6        7     2          2   Medium\n",
       "7        8     2          4   Medium\n",
       "8        9     2          2   Medium\n",
       "9       10     2          3   Medium\n",
       "10      11     3          7     High\n",
       "11      12     3          4     High\n",
       "12      13     3          5     High\n",
       "13      14     3          3     High\n",
       "14      15     3          6     High"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the series.map function to add labels to the Dose variable.\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "df_ig['Dose_cat'] = df_ig['Dose'].map(dict(zip(a, b)))\n",
    "\n",
    "df_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89300643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to compare variance around the mean happiness score for each of the groups, so to do this I will\n",
    "# create three new variable objects that can then be passed to the scipy levene method for comparison.\n",
    "\n",
    "cat = df_ig['Dose_cat']\n",
    "scale = df_ig['Happiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba06728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next creating three boolean objects spltting cat up by level/ condition.\n",
    "\n",
    "cat_1 = cat == 'Low'\n",
    "cat_2 = cat == 'Medium'\n",
    "cat_3 = cat == 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d39692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a list of each happiness score broken down by category. Using the above booleans.\n",
    "\n",
    "cat_happ_low = scale[cat_1]\n",
    "cat_happ_med = scale[cat_2]\n",
    "cat_happ_high = scale[cat_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dfcbaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.09169054441260736, pvalue=0.9130204455480186)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now running the Levene's test by passing the above three happiness scores by group objects.\n",
    "# Specifying the mean as measure of centre.\n",
    "\n",
    "levene(cat_happ_low, cat_happ_med, cat_happ_high, center = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd2862",
   "metadata": {},
   "source": [
    "### Degrees of freedom when using scipy levene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77aed87",
   "metadata": {},
   "source": [
    "We can see above that we have a Levene's statistic of F = 0.09 and an associated p-value of p = 0.91. So, this was a non-significant Levene's test. The hull hypothesis for Levene's test is that the variances between the groups are equal, which is the assumption we are seeking to meet to be able to conduct an ANOVA test on the data. Here, as the result was non-significant we can assume homogeneity of variance for our data and are probably safe to run and interpret a standard ANOVA test of whatever our research hypothesis was.\n",
    "\n",
    "Note here that the output for Levene's test using scipy does not give us the degress of freedom. To formally report this result we would want to also report the degrees of freedom as the test statistic for the Levene's test follows an F-distribution. The degrees of freedom can be calculated as follows:\n",
    "\n",
    "- df(between) = k - 1 \n",
    "- df(within) = n - k \n",
    "- df(total) = n - 1\n",
    "\n",
    "Where k is the number of categories/ groups and n is the total number of scores/ participants.\n",
    "\n",
    "The degrees of freedom can easily be calculated on a small dataset like that above with only 15 participants and 3 groups.\n",
    "\n",
    "- df(between) = 3 - 1 = 2 \n",
    "- df(within) = 15 - 3 = 12 \n",
    "- df(total) = 15 - 1 = 14\n",
    "\n",
    "To formally report the above result of the Levene's test we only need to include the df(between) and df(within) and so would format the result of Levene's test as: F(2, 12) = 0.09, p = 0.91.\n",
    "\n",
    "We could create some formulas to work out the degrees of freedom for us. This may be helpful with a large dataset with a large number of groups being comapred. The code below illustrates how to do this using the existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ed2c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, we find k (number of groups) and n (number of scores or participants).\n",
    "\n",
    "k = len(pd.unique(cat))\n",
    "n = pd.crosstab(cat, scale).sum().sum()\n",
    "\n",
    "k, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1c2139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With these values we can find the degrees of freedom by adding the objects k and n into the degrees of freedom formula above.\n",
    "\n",
    "df_between = k - 1\n",
    "df_within = n - k\n",
    "df_total = n - 1\n",
    "\n",
    "df_between, df_within, df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfe106",
   "metadata": {},
   "source": [
    "## Mauchly's Test of Sphericity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333edada",
   "metadata": {},
   "source": [
    "As stated in the opening section, Mauchly's test of Sphericity is a repeated measures equivalent to the Levene's test that looks to see if the variance of difference scores taken from the same participant between all pairs of groups in the categorical variable are equal. \n",
    "\n",
    "Below I demonstrate Mauchly's test using the sphericity method from the pingouin package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ef6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pingouin.\n",
    "\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b58ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Framing</th>\n",
       "      <th>Questions_LTCol</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.277222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.444483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.082127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.704305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.852132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PersonID  Framing  Questions_LTCol   Arousal\n",
       "0         1        1                1  1.277222\n",
       "1         2        1                1  6.444483\n",
       "2         3        1                1  1.082127\n",
       "3         4        1                1  2.704305\n",
       "4         5        1                1  2.852132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing a dataset with a repeated measures categorical variable to analyse. \n",
    "\n",
    "df_eda = pd.read_csv('EDA Data Long Thin.csv')\n",
    "\n",
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb30278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpherResults(spher=False, W=0.9177060268963375, chi2=6.698497399305895, dof=2, pval=0.03511072289245792)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running Mauchly's test using the pg.sphericity method.\n",
    "\n",
    "pg.sphericity(data = df_eda, dv = 'Arousal', subject = 'PersonID', within = 'Questions_LTCol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb098bfe",
   "metadata": {},
   "source": [
    "The result shows Mauchly's test to be statistically significant (p = 0.04) indicating that the assumption of sphericity has been violated. Like Levene's test, as a test of assumption the null hypothesis for Mauchly's is that the difference scores across categories are the same. As such, a significant Mauchly's test means we cannot assume this and probably need to conduct some type of robust statistical analysis to test our research hypothesis, rather than run a standard ANOVA. \n",
    "\n",
    "You can see from the above output that Mauchly's tests returns a test statistic (W), a chi2 value, degrees of freedom for the chi2 test, a p-value (pval), and a boolean value indicating that the assumption of sphericity is False. This could be formally reported as follows:\n",
    "\n",
    "Mauchly's W: X2(2) = 6.70, p = 0.04. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4f94a",
   "metadata": {},
   "source": [
    "## Shapiro - Wilk Test of Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34c76d",
   "metadata": {},
   "source": [
    "The Shapiro - Wilk test can be used to test the normality of a variables distribution. Below I conduct a test on a variable from an independent groups design and to check for normality at each level of a repeated measures factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c496b43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>pval</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Happiness</th>\n",
       "      <td>0.953505</td>\n",
       "      <td>0.581245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  W      pval  normal\n",
       "Happiness  0.953505  0.581245    True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of normality on the happiness variable from the puppies dataset. \n",
    "\n",
    "pg.normality(df_ig['Happiness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b87038",
   "metadata": {},
   "source": [
    "This returns a pandas table of values showing the Shapiro - Wilk test statistic (W), the p-value, and a Boolean value stating whether the variable's distribution can be classed as normal (True/ False). \n",
    "\n",
    "As a test of assumption, the null hypothesis for the test is that the distribution is normal. A significant result would indicate deviation from normality. In this case the result is non-significant indicating that it is probably safe to assume the variable does not deviate excessively from a normal distribution. The could be formally reported as:\n",
    "\n",
    "W = 0.95, p = 0.58. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31772c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>pval</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Questions_LTCol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.680608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984343</td>\n",
       "      <td>0.437271</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983814</td>\n",
       "      <td>0.408795</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        W      pval  normal\n",
       "Questions_LTCol                            \n",
       "1                0.988241  0.680608    True\n",
       "2                0.984343  0.437271    True\n",
       "3                0.983814  0.408795    True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of normality for the repeated measures design. Note here that we need to include the data, the DV and the \n",
    "# categorical/ grouping variable as parameters. \n",
    "\n",
    "pg.normality(data = df_eda, dv = 'Arousal', group = 'Questions_LTCol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064329f4",
   "metadata": {},
   "source": [
    "The output we get is similar to when we just used a single scale variable. This time, however, each group of the categorical variable has been assessed for normality individually. In this case we can see that the distribution of scores for all three groups appears to not deviate from normality as all three have non-significant p-values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
